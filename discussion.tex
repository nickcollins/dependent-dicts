%% \section{Discussion and Related Work}
\section{Discussion}
\label{sec:Discussion}

\subsection{Design Tradeoffs of Difficult Destruction}
\label{sec:Discussion:Tradeoffs}

Is it possible to have a data structure that possesses all four properties?
%
Probably not.

\SemInj{} requires canonical ordering and deduplication, and \SemTot{} means that the canonical order and deduplication have to come from how the data is interpreted rather than how it is organized.
%
%The following section shows that this non-literal interpretation causes issues with ease of destruction.
%As a result $\hdots$
%% \parahead{The Difficulty of Destruction}
%\parahead{Not-So-Easy Destruction}
%
The non-literal way in which key data is interpreted for delta dictionaries means that it is not safe for client code to work with the raw data directly --- rather, all interaction with the data must be encapsulated in library functions.

Unfortunately, this includes \emph{destruction}; an interaction which
normally goes through the very natural, elegant, and well-supported mechanism of pattern matching is now
only available through the library function \verb+destruct+. \autoref{thm:EzDstr} proves that this function
destructs the \dd{} in essentially the same way that a case expression destructs a list of pairs (although
the order in which bindings are plucked away is arbitrary from the client's perspective).

\verb+destruct+ achieves the same purpose as typical pattern matching (albeit more awkwardly), but because it
does not harness the primitive notions of pattern matching and structure, it does not establish structural
decrease on the dictionary object, which may break out-of-the-box \emph{structural recursion} in the likely case
of recursion on the subdictionary \texttt{dd'}.
Structural recursion essentially means that at least one argument to any recursive call must be the direct child of the same argument to the outer call.
For example, let's say a function \texttt{f} takes a tree \texttt{t} and a natural \texttt{n} as arguments ---
a recursive call inside \texttt{f} would have to either be on the left or right subtree of \texttt{t}, or on \texttt{n - 1}.
Proof languages like Agda and Coq generally require that all functions be structurally recursive in order to ensure that they terminate,
as non-terminating functions can introduce logical contradictions.

Structural recursion is often easy to establish when some argument to a function is destructed, and then recursive calls are made using the destructed subcomponents.
In the case where destruction is done by way of a function, instead of pattern matching,
the system has no way to assert that the output of the function is a subcomponent of one of its inputs,
preventing out-of-the-box structural recursion.
It may yet be possible, though, to establish structural recursion by adding an extra parameter which tracks some property of the original parameters and which decreases with every recursive call.
In the case of dictionaries, the natural choice is the size of the dictionary --- \texttt{dd'} returned by \verb+destruct+ has size exactly one less than the input \texttt{dd}.
Having to add another parameter, as well as a proof that it is equal to the dictionary's size, is painful, requiring a lot more effort and boilerplate than out-of-the-box structural recursion.
However, it does mean that proving theorems about destruction and iteration of \dds{} is still \emph{possible}.

The following additional theorem facilitates this awkward alternative means of establishing structural recursion:

\begin{alltt}
  extend-size :
    \altFAll\{V\} \{dd : DD V\} \{k : K\} \{v : V\} \altRArr
      k \altNIn dd \altRArr
      || dd ,, (k , v) || = 1 + || dd ||
\end{alltt}

Because destruction of basic {\sal}s and {\cal}s can generally rely on out-of-the-box structural recursion, \dds~ fall short of \EzDstr.
Nonetheless, they are still better than {\fpf}s in this regard, seeing as it is not only hard but impossible to destruct {\fpf}s.

Because satisfying all four properties seems unattainable,
there seems to be an
inherent trade-off between desirable properties. In cases where \SemTot{} and \EqDec{} are critical,
and there is little to no need to destruct dictionaries, \dds{} seem to be a clear winner over
the conventional solutions. But in cases where \SemTot{} is not so important,
but inspection or destruction are, {\cal}s may be preferable.

\subsection{Potential Practical Applications}
\label{sec:Discussion:Generality}

\parahead{Generality of Case Study}

The scenario in \autoref{sec:CaseStudy} may seem contrived, but it is actually a simplification of a real task faced by the author:
%
to complete an Agda formalization of Smyth~\citep{smyth}, a program synthesis technique which uses
natural semantics (\ie{} big-step, environment-based evaluation) and which requires assertions.
%
The development in \autoref{sec:CaseStudy} captures the essence of the much larger development~\citep{github:smyth:agda} for Smyth.
%
Although that development has not been completed, some of the challenges it presented --- summed up in \autoref{sec:CaseStudy} --- necessitated the invention of \dds.

Perhaps, instead of using \dds, these issues could be worked around, by changing or dropping some of our criteria?
In many cases, substitution can be used to avoid environments. However, environments are often preferred --- usually in combination with big-step operational semantics --- because
they allow the formalization to more closely resemble the implementation of a simple recursive interpreter. Furthermore,
Smyth has hole closures in addition to lambda closures, so closing over environments would be necessary regardless.

Contraction and exchange are not always necessary properties for program foundation judgments ---
rather, substructural type systems, by definition, deliberately violate one or both of these properties.%
\footnote{\hspace{0.01in}Technically, some substructural type systems (\eg{} \emph{relevant} type systems) uphold contraction and exchange but violate \emph{weakening}.}
That said, a judgment should generally uphold the structural properties unless there is a strong and explicit
reason not to. Proving the right properties
is both a matter of good housekeeping and necessity: they are standard
considerations because they arise very naturally in any other
interesting metatheory, and the inability to prove them is often a large red flag indicating a bug in the judgment's definition.
Because contraction and exchange are properties of \dds{} themselves,
the proofs of these properties for one or many judgments come ``for free.''
Additionally, the useful properties of \dds{} may greatly reduce the difficulty of the usually
more judgement-specific proof of \emph{weakening}.

It may not seem useful to assert that two functions are intensionally identical, but if assertion is relaxed,
so as to test consistency or partially extensional equality instead of purely intensional equality,
it would require environments that are destructible.
Scenarios which require destructibility but not \EqDec{} lead to the same conclusions,
seeing as these columns are identical in \autoref{fig:prop-summary}.

In addition to breaking strict positivity, refinement proofs (\eg{} validity proofs that must be packaged with \cal{}s) can be the source of less severe pain points in
a broader range of circumstances.
The ability to refine ordinary types with proofs of validity is one of the most interesting and useful benefits of
dependently-typed languages, and this power should be appreciated. However, refining with proof terms can
come at a practical cost, so even in dependently-typed languages, there is high value in avoiding refinements
whenever possible (or at least whenever profitable). The practical cost of refinements is that proof terms
do not possess the properties \SemInj{} or \EqDec: due to \emph{proof relevance}, two proofs of
the same property may be unequal, and due to the fact that proof terms may contain functions, proof terms do not
possess \EqDec{} in the general case. Thus, \SemTot{} --- which obviates the need for refinement --- has
a lot of practical value in many general cases beyond those where it is absolutely necessary to appease the
positivity checker.

\parahead{Dictionaries vs. Custom Datatypes}

Dictionaries are not always used to represent environments in formalizations of programming language theory.

When the order of bindings does not matter, dictionaries are a natural choice for type contexts.
%
But if types defined ``later'' in inner scopes, can refer to types defined ``earlier'' in outer scopes, then order-insensitive dictionaries are inherently inappropriate.
%
This is the case for languages that support subtyping --- notably, the subject of the POPLmark Challenge~\citep{POPLmark}.
%
Linear type systems, on the other hand, require sensitivity to duplicate insertions, so duplication-insensitive dictionaries are inappropriate for them as well \citep{StructProp}.
%
Though {\sal}s remain the most natural choice in these cases, future work could explore data structures that are sensitive to ordering but not duplication, or vice versa.

The use of dictionaries is furthermore avoided in many systems that use substitution rather than environments
%
in defining the dynamic semantics of a language, as well as the many systems that avoid named variables altogether by using De Bruijn indices or comparable techniques --- see \emph{Certified Programming with Dependent Types}~\cite[Library Firstorder]{cpdt} for an introduction.

For these reasons, many existing formalisms make little use of order-and-duplication-insensitive dictionaries. 
%
However, as mechanized formalisms becomes increasingly popular, for an ever-broadening scope of applications,
%
it seems inevitable that a programming utility as fundamental as dictionaries will eventually become ubiquitous, at which point it will be important to have the
%
best implementations at our disposal.

\subsection{Related Work}
\label{sec:Discussion:Related}

How often are different dictionary representations used?

\parahead{Conventional Representations}
%
Due to their simplicity, basic {\sal}s are perhaps the most typical implementation for dictionaries.
%
But because \SemInj{} is so important in simplifying proofs, {\fpf}s also see significant use --- in key works such as \emph{Software Foundations}~\cite[Maps]{Pierce:SF1} --- despite requiring a bit of extra overhead.

\Cals{} seem to get little use, perhaps because working with validity proofs might add more hassle than \SemInj{} alleviates.
%
\Cals{} are defined in the Coq standard library as \texttt{FMapList} \citep{FMapList}; a GitHub search for \texttt{FMapList} shows $304$ results,
%
whereas a search for \texttt{FMapAVL} shows $474$ results, suggesting that {\cal}s have been found to be less useful than high-performance implementations.
%
A search for \texttt{FunctionalExtensionality} \citep{FunExt}, on the other hand, turns up $4916$ results, though most of these are probably unrelated to dictionaries.%
\footnote{\hspace{0.01in}%
%
These searches and can be reproduced by URLs of the form:
\url{https://github.com/search?l=\&p=3\&q=FMapList+language\%3ACoq\&ref=advsearch\&type=Code },
replacing \texttt{FMapList} with \texttt{FMapAVL} and \texttt{FunctionalExtensionality}.
%
Accessed August 23, 2020.
%
}
%
\citet{Amorim:fmap} provides a more comprehensive treatment of {\cal}s, augmenting them with a functional interface so that the client can
%
use them as though they were {\fpf}s (note that this is different from having a \fpf{} augmented with keys).

% github searches
% funext        : 4916
% FMapInterface : 504
% FMapAVL       : 474
% FMapList      : 304

\parahead{Performance Concerns}
%
It was noted above that AVL implementations are apparently more popular than {\cal}s, and as more software is mechanized (\ie{} programmatically formalized), performance is likely to become an
%
even greater concern than it is today. In cases where there is no extraction step (which transpiles non-proof parts of a mechanization into a conventional, non-proof language), and the proof language is also the language that will be executed,
%
there may be no choice but to use implementations that are high-performance but theoretically unwieldy.

However, it seems more appropriate, especially with
%
fundamental utilities such as dictionaries, to either extract or translate the mechanization into an implementation language that defines these utilities natively
%
by way of highly efficient implementations such as hashtables or red-black trees. This extraction may not be completely fidelitous, since it will be using a
%
different data structure in the implementation than was used in the proofs, but presumably the implementation's version of dictionaries is well-tested and bug-free,
%
and its definition of equality is, at least for fundamental utilities such as dictionaries, extensional and decidable.

Regardless, even if unperformant implementations
%
cannot be used for code that will be run, they may be useful for parts of the code which are only used for proofs and will not be executed.

\subsection{When \SemTot{} Doesn't Matter}
The spirit of \SemTot{} --- that all values of a type are valid by construction, without requiring additional overhead --- has broad utility.
%
However, the particular criterion that the type involve no proof terms in order to uphold validity can be arbitrary in cases where the proof type is ``\emph{\prop}''.
%
To be \prop, all values of the type must be equal, \ie{} for any $x,y : T$, $x = y$.
%
As such, a \prop{} proof type is \extensional{} and has \EqDec, so it does not suffer from the problems that can arise when using non-\prop{} proofs.
%
With the use of proof terms being no more cumbersome than the use of any other type, the requirement that a semantically total approach not involve any proof terms becomes useless.

Owing to this observation, there is yet another approach, not yet discussed, which fulfills all the core properties, besides \SemTot, which it technically violates but fulfills in spirit.
%
This approach is a variant of \cal{}s, but instead of having a proof of the whole structure's correctness on the outside, an inequality proof is baked into the ``cons'' constructor.
%
Since it is generally easy to establish the \propity{} of less-than relations, this approach is \extensional{} and has \EqDec,
%
and since the data is stored literally, it's almost as trivial to destruct as \cal{}s.
%
Because the proofs only refer to the key type, and not the value type nor the dictionary type, there are no issues with the positivity checker,
%
and since the proofs are buried deep in the data structure, the client never has to worry about managing them.
%
Essentially, the purposes of \SemTot{} are satisfied even if its technical definition is not.
%
Furthermore, this approach does not require bijection to the naturals, only that the less-than relation is proven to be \prop,
%
and is substantially simpler to implement than \dds.

There are perhaps many ways to implement this proofs-on-the-inside (POTI) \cal{} approach --- the one detailed below adds a helper parameter which indexes a list with its least key,
%
permitting a comparison between that list and some lesser key without inspecting the list:
%
\begin{lstlisting}
data potical' (V : Set) : Maybe Nat $\rightarrow$ Set where
  PINone : potical' V None
  PISngl : (n : Nat) $\rightarrow$ V $\rightarrow$ potical' V (Some n)
  PIMore : $\forall${n2} $\rightarrow$ (n1 : Nat) $\rightarrow$ V $\rightarrow$
           n1 < n2 $\rightarrow$
           potical' V (Some n2) $\rightarrow$
           potical' V (Some n1)

data potical (V : Set) : Set where
  PI : $\forall${mn} $\rightarrow$ potical' V mn $\rightarrow$ potical V
\end{lstlisting}

In some sense, the POTI \cal{} approach is isomorphic to \dds.
%
A proof that $a < b$ might constitute a natural number $n$ along with a proof that $b = a + 1 + n$.
%
This $n$ corresponds to a delta in a \dd.
%
Effectively, a delta in a \dd{} is interpreted in a similar manner to how a less-than proof term is interpreted.
%
Consequently, a conversion function between this approach and \dds{} does a simple pass over the mappings, transforming deltas into less-than proofs:
%
\begin{lstlisting}
convert' : $\forall${V} $\rightarrow$ (n : Nat) $\rightarrow$ V $\rightarrow$ dl V $\rightarrow$ (potical' V (Some n))
convert' n v [] = PISngl n v
convert' n1 v1 ((n2 , v2) :: dl)
  = PIMore n1 v1 (n<m$\rightarrow$n<s+m n<1+n) <| convert' (n2 + 1+ n1) v2 dl

convert : $\forall${V} $\rightarrow$ dl V $\rightarrow$ potical V
convert []              = PI PINone
convert ((n , v) :: dl) = PI <| convert' n v dl
\end{lstlisting}

The important difference, then, is that POTI \cal{}s contain redundant information, whereas \dds{} do not.
%
Each mapping for the POTI \cal{} approach records three items --- $n1$, $n2$, and the proof that $n1 < n2$, whereas a \dd{} mapping records only the delta.
%
The POTI \cal{} approach achieves the spirit of \SemTot{}, despite these redundancies, because the dependent type system is capable of ensuring invariants in redundant data.
%
However, in less powerful type systems, redundancy inherently opens the door to invalidity.
%
As such, techniques that eliminate all redundancy may be useful in weaker type systems, while dependent type systems can appropriately manage redundancy by way of \prop{} proofs.

The inability to make POTI \cal{}s work without using proof-aware type-systems suggests that \dds{}, or similar techniques, may still be useful in conventional languages.
%
While \dds{} themselves are unperformant and thus unlikely to be a good choice in conventional settings,
%
the strategy that they illustrate --- of squeezing out all redundancy in order to ensure invariants --- may be applicable to more efficient data types.
%
This strategy may also be useful for invariants that cannot be made \prop, \eg{} implication invariants, which are represented as arrow types.

Since the POTI \cal{} approach is easy to implement and effortlessly checks off all the criteria, it's surprising that it seems to see little to no practical use or textbook discussion.
%
As aforementioned, many tasks don't require the use of dictionaries per se, whereas those that do may not require that the implementation satisfy all four core properties.
%
Nonetheless, the general utility of dictionaries and the limitations suffered by implementations that fail to satisfy one of the properties suggest that this approach,
%
or some other suitable approach, ought to be implemented and widely used in the near future.
%
Further development and study of this and related approaches may be worthwhile areas for future work.

\subsection{Conclusion and Future Work}
\label{sec:Discussion:Conclusion}
%
This paper discusses the important properties \SemTot, \SemInj, \EqDec, and \EzDstr, and offers an implementation for dictionaries that (mostly) fulfills these properties.

Future work could consider implementations for other key utilities, such as trees or graphs, that satisfy these properties.
%
Doing so could be far more challenging.
%
It is relatively easy to simultaneously satisfy \SemTot{} and \SemInj{} for list-like structures such as dictionaries,
%
but much more awkward to do so for highly structural data such as graphs. For unlabeled graphs in particular, establishing a one-to-one correspondence between values and
%
semantic meanings requires understanding of the graph isomorphism problem, which involves complex algebra.

% Other things to consider mentioning, but probably not
% - try to make sense of https://github.com/arthuraa/coq-utils/blob/master/theories/nominal.v
% - Coq also has FMapPositive, which is a tree based on the binary representation
% - something something explicit substitutions, Abadi et al. POPL 1990.
% - Look deeper into TDD with Idris
